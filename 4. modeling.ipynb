{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "import copy\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model :\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model param function\n",
    "def create_model_param():\n",
    "  \"\"\"Create the model objedts\"\"\"\n",
    "  knn_params = {\n",
    "    'n_neighbors' : [50, 100, 200],\n",
    "  }\n",
    "  \n",
    "  lgr_params = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C' : [0.01, 0.1],\n",
    "    'max_iter' : [100, 300, 500]\n",
    "  }\n",
    "  \n",
    "  xgb_params = {\n",
    "    'n_estimators' : [5, 10, 25, 50]\n",
    "  }\n",
    "  \n",
    "  # create model params\n",
    "  list_of_param = {\n",
    "    'KNeighborsClassifier' : knn_params,\n",
    "    'LogisticRegression' : lgr_params,\n",
    "    'XGBClassifier' : xgb_params\n",
    "  }\n",
    "  \n",
    "  return list_of_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object function\n",
    "def create_model_object():\n",
    "  \"\"\"Create the model objects\"\"\"\n",
    "  print('Creating model objects')\n",
    "  \n",
    "  # create model objects\n",
    "  knn = KNeighborsClassifier()\n",
    "  lgr = LogisticRegression(solver='liblinear')\n",
    "  xgb = XGBClassifier()\n",
    "  \n",
    "  # create list of model\n",
    "  list_of_model = [\n",
    "    {'model_name' : knn.__class__.__name__, 'model_object' : knn},\n",
    "    {'model_name' : lgr.__class__.__name__, 'model_object' : lgr},\n",
    "    {'model_name' : xgb.__class__.__name__, 'model_object' : xgb}\n",
    "  ]\n",
    "  \n",
    "  return list_of_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model function\n",
    "def train_model():\n",
    "  \"\"\"Function to get the best model\"\"\"\n",
    "  # load dataset\n",
    "  X_train = joblib.load('data/output/X_train_clean.pkl')\n",
    "  y_train = joblib.load('data/output/y_train_clean.pkl')\n",
    "  X_valid = joblib.load('data/output/X_valid_clean.pkl')\n",
    "  y_valid = joblib.load('data/output/y_valid_clean.pkl')\n",
    "  \n",
    "  # create list of params & models\n",
    "  list_of_param = create_model_param()\n",
    "  list_of_model = create_model_object()\n",
    "  \n",
    "  # list of trained model\n",
    "  list_of_tuned_model = {}\n",
    "  \n",
    "  # train model\n",
    "  for base_model in list_of_model:\n",
    "    # current condition\n",
    "    model_name = base_model['model_name']\n",
    "    model_obj = copy.deepcopy(base_model['model_object'])\n",
    "    model_param = list_of_param[model_name]\n",
    "    \n",
    "    # debug message\n",
    "    print('Training model :', model_name)\n",
    "    \n",
    "    # create model object\n",
    "    model = RandomizedSearchCV(estimator=model_obj,\n",
    "                               param_distributions=model_param,\n",
    "                               n_iter=5,\n",
    "                               cv=5,\n",
    "                               random_state=123,\n",
    "                               n_jobs=1,\n",
    "                               verbose=10,\n",
    "                               scoring='roc_auc')\n",
    "    \n",
    "    # train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    # get score\n",
    "    train_score = roc_auc_score(y_train, y_pred_proba_train)\n",
    "    valid_score = roc_auc_score(y_valid, y_pred_proba_valid)\n",
    "    \n",
    "    # append \n",
    "    list_of_tuned_model[model_name] = {\n",
    "      'model': model,\n",
    "      'train_auc': train_score,\n",
    "      'valid_auc': valid_score,\n",
    "      'best_params': model.best_params_\n",
    "    }\n",
    "    \n",
    "    print('Done training')\n",
    "    print('')\n",
    "  \n",
    "  joblib.dump(list_of_param, 'data/model/list_of_param.pkl')\n",
    "  joblib.dump(list_of_model, 'data/model/list_of_model.pkl')\n",
    "  joblib.dump(list_of_tuned_model, 'data/model/list_of_tuned_model.pkl')\n",
    "  \n",
    "  return list_of_param, list_of_model, list_of_tuned_model\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n",
      "Training model : KNeighborsClassifier\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_neighbors=50..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANAS SATRIA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/3] END ...............n_neighbors=50;, score=0.858 total time=   0.2s\n",
      "[CV 2/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 2/5; 1/3] END ...............n_neighbors=50;, score=0.853 total time=   0.1s\n",
      "[CV 3/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 3/5; 1/3] END ...............n_neighbors=50;, score=0.846 total time=   0.2s\n",
      "[CV 4/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 4/5; 1/3] END ...............n_neighbors=50;, score=0.851 total time=   0.2s\n",
      "[CV 5/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 5/5; 1/3] END ...............n_neighbors=50;, score=0.856 total time=   0.3s\n",
      "[CV 1/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 1/5; 2/3] END ..............n_neighbors=100;, score=0.858 total time=   0.3s\n",
      "[CV 2/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 2/5; 2/3] END ..............n_neighbors=100;, score=0.855 total time=   0.2s\n",
      "[CV 3/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 3/5; 2/3] END ..............n_neighbors=100;, score=0.847 total time=   0.3s\n",
      "[CV 4/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 4/5; 2/3] END ..............n_neighbors=100;, score=0.852 total time=   0.3s\n",
      "[CV 5/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 5/5; 2/3] END ..............n_neighbors=100;, score=0.856 total time=   0.3s\n",
      "[CV 1/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 1/5; 3/3] END ..............n_neighbors=200;, score=0.857 total time=   0.4s\n",
      "[CV 2/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 2/5; 3/3] END ..............n_neighbors=200;, score=0.853 total time=   0.3s\n",
      "[CV 3/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 3/5; 3/3] END ..............n_neighbors=200;, score=0.844 total time=   0.4s\n",
      "[CV 4/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 4/5; 3/3] END ..............n_neighbors=200;, score=0.852 total time=   0.4s\n",
      "[CV 5/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 5/5; 3/3] END ..............n_neighbors=200;, score=0.856 total time=   0.4s\n",
      "Done training\n",
      "\n",
      "Training model : LogisticRegression\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 1/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 2/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.854 total time=   0.0s\n",
      "[CV 3/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 3/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.847 total time=   0.0s\n",
      "[CV 4/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 4/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.849 total time=   0.0s\n",
      "[CV 5/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 5/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.855 total time=   0.0s\n",
      "[CV 1/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 1/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 2/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.853 total time=   0.0s\n",
      "[CV 3/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 3/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.843 total time=   0.0s\n",
      "[CV 4/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 4/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.847 total time=   0.0s\n",
      "[CV 5/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 5/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.852 total time=   0.0s\n",
      "[CV 1/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 1/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 2/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.853 total time=   0.0s\n",
      "[CV 3/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 3/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.843 total time=   0.0s\n",
      "[CV 4/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 4/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.847 total time=   0.0s\n",
      "[CV 5/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 5/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.852 total time=   0.0s\n",
      "[CV 1/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 1/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.856 total time=   0.0s\n",
      "[CV 2/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 2/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.854 total time=   0.0s\n",
      "[CV 3/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 3/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.848 total time=   0.0s\n",
      "[CV 4/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 4/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.849 total time=   0.0s\n",
      "[CV 5/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 5/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.855 total time=   0.0s\n",
      "[CV 1/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 1/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.856 total time=   0.0s\n",
      "[CV 2/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 2/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.854 total time=   0.0s\n",
      "[CV 3/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 3/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.847 total time=   0.0s\n",
      "[CV 4/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 4/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.849 total time=   0.0s\n",
      "[CV 5/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 5/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.854 total time=   0.0s\n",
      "Done training\n",
      "\n",
      "Training model : XGBClassifier\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START n_estimators=5..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANAS SATRIA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/4] END ...............n_estimators=5;, score=0.857 total time=   1.2s\n",
      "[CV 2/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 2/5; 1/4] END ...............n_estimators=5;, score=0.851 total time=   0.0s\n",
      "[CV 3/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 3/5; 1/4] END ...............n_estimators=5;, score=0.846 total time=   0.0s\n",
      "[CV 4/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 4/5; 1/4] END ...............n_estimators=5;, score=0.849 total time=   0.0s\n",
      "[CV 5/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 5/5; 1/4] END ...............n_estimators=5;, score=0.850 total time=   0.0s\n",
      "[CV 1/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 1/5; 2/4] END ..............n_estimators=10;, score=0.859 total time=   0.0s\n",
      "[CV 2/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 2/5; 2/4] END ..............n_estimators=10;, score=0.854 total time=   0.0s\n",
      "[CV 3/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 3/5; 2/4] END ..............n_estimators=10;, score=0.851 total time=   0.0s\n",
      "[CV 4/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 4/5; 2/4] END ..............n_estimators=10;, score=0.851 total time=   0.0s\n",
      "[CV 5/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 5/5; 2/4] END ..............n_estimators=10;, score=0.855 total time=   0.0s\n",
      "[CV 1/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 1/5; 3/4] END ..............n_estimators=25;, score=0.858 total time=   0.0s\n",
      "[CV 2/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 2/5; 3/4] END ..............n_estimators=25;, score=0.853 total time=   0.0s\n",
      "[CV 3/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 3/5; 3/4] END ..............n_estimators=25;, score=0.850 total time=   0.0s\n",
      "[CV 4/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 4/5; 3/4] END ..............n_estimators=25;, score=0.850 total time=   0.0s\n",
      "[CV 5/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 5/5; 3/4] END ..............n_estimators=25;, score=0.855 total time=   0.0s\n",
      "[CV 1/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 1/5; 4/4] END ..............n_estimators=50;, score=0.852 total time=   0.0s\n",
      "[CV 2/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 2/5; 4/4] END ..............n_estimators=50;, score=0.847 total time=   0.1s\n",
      "[CV 3/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 3/5; 4/4] END ..............n_estimators=50;, score=0.846 total time=   0.0s\n",
      "[CV 4/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 4/5; 4/4] END ..............n_estimators=50;, score=0.848 total time=   0.0s\n",
      "[CV 5/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 5/5; 4/4] END ..............n_estimators=50;, score=0.849 total time=   0.0s\n",
      "Done training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running the train model function\n",
    "list_of_param, list_of_model, list_of_tuned_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': {'model': RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_neighbors': [50, 100, 200]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.8602548044426367,\n",
       "  'valid_auc': 0.8628637399439292,\n",
       "  'best_params': {'n_neighbors': 100}},\n",
       " 'LogisticRegression': {'model': RandomizedSearchCV(cv=5, estimator=LogisticRegression(solver='liblinear'),\n",
       "                     n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'C': [0.01, 0.1],\n",
       "                                          'max_iter': [100, 300, 500],\n",
       "                                          'penalty': ['l1', 'l2']},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.8526284453004676,\n",
       "  'valid_auc': 0.8550904112115946,\n",
       "  'best_params': {'penalty': 'l2', 'max_iter': 500, 'C': 0.01}},\n",
       " 'XGBClassifier': {'model': RandomizedSearchCV(cv=5,\n",
       "                     estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None, device=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None, feature_types=None,\n",
       "                                             gamma=None, grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             learning_rate...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None, max_depth=None,\n",
       "                                             max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             multi_strategy=None,\n",
       "                                             n_estimators=None, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             random_state=None, ...),\n",
       "                     n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_estimators': [5, 10, 25, 50]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.8809734700340202,\n",
       "  'valid_auc': 0.8646928753961602,\n",
       "  'best_params': {'n_estimators': 10}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show list of tuned model\n",
    "list_of_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model function\n",
    "def get_best_model():\n",
    "  \"\"\"Function to get the best model\"\"\"\n",
    "  # load tuned model\n",
    "  list_of_tuned_model = joblib.load('data/model/list_of_tuned_model.pkl')\n",
    "  \n",
    "  # get the best model\n",
    "  best_model_name = None\n",
    "  best_model = None\n",
    "  best_performance = -99999\n",
    "  best_model_param = None\n",
    "  \n",
    "  for model_name, model in list_of_tuned_model.items():\n",
    "    if model['valid_auc'] > best_performance:\n",
    "      best_model_name = model_name\n",
    "      best_model = model['model']\n",
    "      best_performance = model['valid_auc']\n",
    "      best_model_param = model['best_params']\n",
    "      \n",
    "  # save the best model\n",
    "  joblib.dump(best_model, 'data/model/best_model.pkl')\n",
    "  \n",
    "  # print\n",
    "  print('=============================================')\n",
    "  print('Best model         :', best_model_name)\n",
    "  print('Metric score       :', best_performance)\n",
    "  print('Best model params  :', best_model_param)\n",
    "  print('=============================================')\n",
    "  \n",
    "  return best_model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Best model         : XGBClassifier\n",
      "Metric score       : 0.8646928753961602\n",
      "Best model params  : {'n_estimators': 10}\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# show the result of the best model and parameters\n",
    "best_model = get_best_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
